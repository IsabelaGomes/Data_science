{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMJwwDFRv82t"
   },
   "source": [
    "# Regressor de preços de casas\n",
    "Nesse exercício, aplicaremos modelos de regressão na predição de preços de casas na Califórnia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swRxhNZ4wVLI"
   },
   "source": [
    "Primeiramente, execute a célula abaixo para ler os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "id": "vB_CPWkbqUm7",
    "outputId": "7758689a-62c6-4e51-9a45-1b1fd6df50ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-114.31</td>\n",
       "      <td>34.19</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.4936</td>\n",
       "      <td>66900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-114.47</td>\n",
       "      <td>34.40</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1.8200</td>\n",
       "      <td>80100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-114.56</td>\n",
       "      <td>33.69</td>\n",
       "      <td>17.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.6509</td>\n",
       "      <td>85700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.64</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.1917</td>\n",
       "      <td>73400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.57</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.9250</td>\n",
       "      <td>65500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
       "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
       "2    -114.56     33.69                17.0        720.0           174.0   \n",
       "3    -114.57     33.64                14.0       1501.0           337.0   \n",
       "4    -114.57     33.57                20.0       1454.0           326.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \n",
       "0      1015.0       472.0         1.4936             66900.0  \n",
       "1      1129.0       463.0         1.8200             80100.0  \n",
       "2       333.0       117.0         1.6509             85700.0  \n",
       "3       515.0       226.0         3.1917             73400.0  \n",
       "4       624.0       262.0         1.9250             65500.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data_aula_05_train.csv')\n",
    "df_test = pd.read_csv('data_aula_05_test.csv')\n",
    "\n",
    "X = df.drop(['median_house_value'],1)\n",
    "y = df['median_house_value']\n",
    "X_test = df_test.drop(['median_house_value'],1)\n",
    "y_test = df_test['median_house_value']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZUOuNrGw0yH"
   },
   "source": [
    "# 1. Separação do conjunto de validação\n",
    "\n",
    "Os dados já vieram separados em conjuntos de treino e teste, porém nós precisamos criar um terceiro conjunto de validação, para podermos avaliar diversos modelos sem ocorrer overfit nos dados de teste. \n",
    "\n",
    "Assim, separe o conjunto principal em um conjunto de treino (80% dos dados) e um de validação (20% dos dados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uE7sNOq-xbxT"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = None, None, None, None\n",
    "\n",
    "######################################################################################\n",
    "# 1. Separe as variáveis X e y em dados de treino e validação, armazenando os resultados nas variáveis acima\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "\n",
    "### Verificação de erros ###\n",
    "assert X_train.shape == (13600, 8) and X_val.shape == (3400, 8) and y_train.shape == (13600,) and y_val.shape == (3400,), 'Erro na separação dos conjuntos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6vzCoj0zH14"
   },
   "source": [
    "# 2. Preprocessamento dos dados \n",
    "\n",
    "Antes de passar os dados para o modelo, é necessário fazer com que eles fiquem aproximadamente na mesma escala. Para isso, vamos considerar duas possibilidades: escalonamento para o intervalo [0,1] e normalização para média 0 e desvio padrão 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JTgc5kAlzMI1"
   },
   "outputs": [],
   "source": [
    "def escalonar(data):\n",
    "\n",
    "    ######################################################################################\n",
    "    # 2. Transforme os dados na variável data para que cada coluna tenha um mínimo de 0 e um máximo de 1\n",
    "    # Obs: a variável data pode ser um DataFrame inteiro ou uma coluna\n",
    "    # O objeto MinMaxScaler da sklearn pode ser útil\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(data)\n",
    "    scaled_data = scaler.transform(data)\n",
    "    return scaled_data    \n",
    "    \n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "### Verificação de erros ###\n",
    "assert escalonar(X_train).shape == X_train.shape, 'Os dados retornados devem ter o mesmo formato dos originais'\n",
    "assert np.all(np.abs(np.max(escalonar(X_test)) - 1) < 1e-3) and np.all(np.abs(np.min(escalonar(X_test))) < 1e-3), 'Os dados retornados devem ter um mínimo de 0 e um máximo de 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YHvDGCx4qZBh"
   },
   "outputs": [],
   "source": [
    "def padronizar(data):\n",
    "\n",
    "    ######################################################################################\n",
    "    # 3. Transforme os dados na variável data para que cada coluna tenha uma média de 0 e um desvio padrão de 1\n",
    "    # Obs: a variável data pode ser um DataFrame inteiro ou uma coluna\n",
    "    # O objeto StandardScaler da sklearn pode ser útil\n",
    "    \n",
    "    stand = StandardScaler()\n",
    "    stand_data = stand.fit_transform(data)\n",
    "    return stand_data \n",
    "\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "### Verificação de erros ###\n",
    "assert padronizar(X_test).shape == X_test.shape, 'Os dados retornados devem ter o mesmo formato dos originais'\n",
    "assert np.all(np.abs(np.std(padronizar(X_test)) - 1) < 1e-3) and np.all(np.abs(np.mean(padronizar(X_test))) < 1e-3), 'Os dados retornados devem ter uma média de 0 e um desvio padrão de 1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cWnEkf22I6W"
   },
   "source": [
    "# 3. Métricas de regressão\n",
    "\n",
    "Uma das principais métricas usadas para regressão é o Erro Quadrático Médio (MSE), que segue a seguinte equação:\n",
    "\n",
    "$\\text{MSE} = \\frac{1}{n}\\sum (Y_{\\text{pred}} - Y_{\\text{true}})^2$\n",
    "\n",
    "\n",
    "Para facilitar a interpretação desse valor, podemos usar a medida R2, que é um valor normalmente entre 0 e 1. Ele é calculado segundo a seguinte equação:\n",
    "\n",
    "$R^2 = 1 - \\frac{\\text{MSE}}{\\text{Var}[Y_{\\text{true}}]}$\n",
    "\n",
    "Assim, implemente as funções para calcular as quantidades acima:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "HQPzUAgn2k8B"
   },
   "outputs": [],
   "source": [
    "def MSE(y_true, y_pred):\n",
    "\n",
    "    ######################################################################################\n",
    "    # 4. Implemente uma função que retorne o erro quadrádico médio\n",
    "    # y_true: valores verdadeiros da variável\n",
    "    # y_pred: valores preditos pelo modelo\n",
    "    \n",
    "    somat = 0\n",
    "    n = len(y_true)\n",
    "    \n",
    "    for i in range(n):\n",
    "        somat += (y_pred[i] - y_true[i])**2\n",
    "        \n",
    "    MSE = somat/n    \n",
    "        \n",
    "    return MSE\n",
    "\n",
    "    ######################################################################################\n",
    "\n",
    "### Verificação de erros ###\n",
    "assert np.abs(MSE(y_test, np.zeros_like(y_test)) - np.mean(y_test**2)) < 1e-3, 'Erro na função MSE'\n",
    "assert np.abs(MSE(y_test, np.ones_like(y_test)*np.mean(y_test)) - np.var(y_test)) < 1e-3, 'Erro na função MSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Uegc9TSs7J2v"
   },
   "outputs": [],
   "source": [
    "def R2(y_true, y_pred):\n",
    "    \n",
    "    ######################################################################################\n",
    "    # 5. Implemente uma função que retorne a medida R2 (pode ser útil reutilizar a função acima)\n",
    "    # y_true: valores verdadeiros da variável\n",
    "    # y_pred: valores preditos pelo modelo\n",
    "    \n",
    "    mse = MSE(y_true, y_pred)\n",
    "    r2 = 1 - (mse/abs(np.var(y_true)))\n",
    "    \n",
    "    return r2\n",
    "    ######################################################################################\n",
    "\n",
    "### Verificação de erros ###\n",
    "assert np.abs(R2(y_test, np.zeros_like(y_test)) + np.mean(y_test)**2 / np.var(y_test)) < 1e-3, 'Erro na função R2'\n",
    "#assert np.abs(R2(y_test, np.mean(y_test))) < 1e-3, 'Erro na função R2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ur9ZnKPC97y6"
   },
   "source": [
    "# 4. Avaliando o modelo KNN\n",
    "\n",
    "Vamos avaliar a performance do modelo KNN para essa tarefa de regressão, com diferentes tipos de preprocessamento (dados originais, escalonados ou padronizados).\n",
    "\n",
    "Para isso, implemente a função para realizar as predições com um modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CWdsXdBq7fXb"
   },
   "outputs": [],
   "source": [
    "def predict(model, X_train, y_train, X_val):\n",
    "    ######################################################################################\n",
    "    # 6. Treine o modelo nos dados de treino e retorne as predições na validação\n",
    "    # A variável model é um modelo da biblioteca sklearn, então a função model.fit pode ser usada\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model.predict(X_val)\n",
    "    \n",
    "    ######################################################################################\n",
    "\n",
    "### Verificação de erros ###\n",
    "assert np.all(predict(DummyRegressor(), X_train, y_train, X_val) == y_train.mean()), 'Erro na função predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "XyrMRdJesoLW"
   },
   "outputs": [],
   "source": [
    "def R2_model(model, X_train, y_train, X_val, y_val):\n",
    "\n",
    "    ######################################################################################\n",
    "    # 7. Retorne a medida R2 do modelo treinado (pode ser útil reutilizar a função anterior)\n",
    "    \n",
    "    y_pred = predict(model, X_train, y_train, X_val)\n",
    "    r2_model = R2(y_val.values, y_pred)\n",
    "    \n",
    "    return r2_model\n",
    "    \n",
    "    ######################################################################################\n",
    "\n",
    "### Verificação de erros ###\n",
    "assert np.abs(R2_model(DummyRegressor(), X_train, y_train, X_val, y_val)) < 1e-3, 'Erro na função R2_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UOJEJAkBwow"
   },
   "source": [
    "Em seguida, vamos avaliar o modelo KNN nos dados de validação com os diferentes tipos de preprocessamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0WxGCWyAfnX",
    "outputId": "1109c56a-b56a-47e4-997e-4379188bee97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 sem preprocessamento: 0.25\n",
      "R2 com escalonamento entre 0 e 1: 0.67\n",
      "R2 com padronização para média 0 e desvio padrão 1: 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "R2_original = None\n",
    "R2_escalonado = None\n",
    "R2_padronizado = None\n",
    "\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "######################################################################################\n",
    "# 8. Avalie o modelo nos dados de validação em três situações, salvando os resultados nas variáveis acima:\n",
    "# 1. Com os dados originais\n",
    "# 2. Com os dados escalonados\n",
    "# 3. Com os dados padronizados\n",
    "#\n",
    "# OBS: não utilize os dados de teste nesse passo, apenas os de treino e validação!\n",
    "\n",
    "R2_original = R2_model(model, X_train, y_train, X_val, y_val)\n",
    "R2_escalonado = R2_model(model, escalonar(X_train), y_train, \n",
    "                         escalonar(X_val), y_val)\n",
    "R2_padronizado = R2_model(model, padronizar(X_train), y_train, \n",
    "                         padronizar(X_val), y_val)\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "print('R2 sem preprocessamento: %.2f' % R2_original)\n",
    "print('R2 com escalonamento entre 0 e 1: %.2f' % R2_escalonado)\n",
    "print('R2 com padronização para média 0 e desvio padrão 1: %.2f' % R2_padronizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZULvBWA7kc1B"
   },
   "source": [
    "Assim, encontre o melhor valor de K para o modelo KNN usando o preprocessamento selecionado no passo anterior, testando todos os valores de K no intervalo de 1 a 30 no conjunto de validação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-bVvBKL3kSEo",
    "outputId": "a85269f6-3954-41b4-881e-aec136469d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de k encontrado: 7\n",
      "Melhor erro R2 na validação encontrado: 0.72\n"
     ]
    }
   ],
   "source": [
    "best_k = 0\n",
    "best_R2 = 0\n",
    "\n",
    "######################################################################################\n",
    "# 9. Encontre o erro do melhor valor de K para o modelo KNN usando o preprocessamento encontrado no passo anterior\n",
    "# OBS: não utilize os dados de teste nesse passo, apenas os de treino e validação!\n",
    "#\n",
    "# Dica: Para criar um modelo KNN com um valor específico de K, use KNeighborsRegressor(n_neighbors = K)\n",
    "\n",
    "k_train = KNeighborsRegressor(n_neighbors = k)\n",
    "k_train.fit(padronizar(X_train), y_train)\n",
    "    \n",
    "for k in range(1,31):\n",
    "    r_knn = R2_model(KNeighborsRegressor(n_neighbors = k), padronizar(X_train), y_train, padronizar(X_val), y_val)\n",
    "    if r_knn > best_R2:\n",
    "        best_R2 = r_knn\n",
    "        best_k = k\n",
    "    \n",
    "######################################################################################\n",
    "\n",
    "print('Melhor valor de k encontrado: %d' % best_k)\n",
    "print('Melhor erro R2 na validação encontrado: %.2f' % best_R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_Jokhfcl0TM"
   },
   "source": [
    "Finalmente, podemos usar o valor ótimo encontrado para avaliar o modelo nos dados de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inPGFfaul5Wg",
    "outputId": "46c7c9b2-2763-4594-94ee-1aabe4a52088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro final encontrado no teste: 0.69\n"
     ]
    }
   ],
   "source": [
    "test_R2 = None\n",
    "\n",
    "######################################################################################\n",
    "# 10. Encontre o erro do modelo encontrado nos dados de teste\n",
    "# Para isso, use o valor de k e o preprocessamento ótimos encontrados\n",
    "test_R2 = R2_model(KNeighborsRegressor(n_neighbors = 7), padronizar(X_train), y_train, padronizar(X_test), y_test)\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "print('Erro final encontrado no teste: %.2f' % test_R2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Aula05",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
